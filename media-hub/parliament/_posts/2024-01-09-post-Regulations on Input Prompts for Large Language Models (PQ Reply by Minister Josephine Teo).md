---
title: Regulations on Input Prompts for Large Language Models (PQ Reply by
  Minister Josephine Teo)
permalink: /media-hub/parliament/09012024b/
date: 2024-01-09
layout: post
description: ""
image: ""
variant: tiptap
---
<h1>Regulations on Input Prompts for Large Language Models to Prevent Disclosure of Confidential Data</h1><p><strong>Fourteenth Parliament of Singapore â€“ Second Session for the Sitting on 9 January 2024</strong></p><h3>Question</h3><p><strong>Dr Tan Wu Meng </strong>asked the Minister for Communications and Information whether the Government has plans to develop in-house artificial intelligence capabilities to ensure that input prompts for large language models need not be processed by private firms not under the purview of the Government, or by cloud computing units located in foreign territories or under foreign jurisdiction or control.&nbsp;</p><p></p><p><strong>Mr Gerald Giam Yean Song </strong>asked the Minister for Communications and Information (a) when using large language models owned by private or foreign companies, how does the Government ensure that confidential data is not disclosed in the input prompts; (b) whether the Government has signed any non-disclosure agreements (NDAs) with these companies; (c) what are the companies that the Government has signed NDAs with; and (d) how does the Government monitor compliance with such NDAs by these companies.</p><p></p><h3>Answer</h3><p><strong>Written answer by Mrs Josephine Teo, Minister for Communications and Information and Minister-in-charge of Smart Nation and Cybersecurity (for the Prime Minister)</strong></p><p>Large language models (LLMs), such as those powering ChatGPT, have the potential to enhance the delivery of public services and the productivity of public officers. We adopt a risk-managed approach for LLMs, consistent with the existing public sector framework for the handling of classified information&nbsp;when using technologies such as internet-based applications and the commercial cloud.</p><p></p><p>Highly&nbsp;sensitive applications and data&nbsp;are not exposed to the Internet. Where use cases involve sensitive data, open-source models&nbsp;may be finetuned&nbsp;for use,&nbsp;but must be&nbsp;deployed on Government servers and computers.</p><p></p><p>For use cases involving less sensitive data, the AI&nbsp;models&nbsp;may be&nbsp;owned and&nbsp;managed by&nbsp;commercial and private&nbsp;companies.&nbsp;Our contracts with these companies are governed by service&nbsp;agreements which include clauses on data handling and security, such as the non-retention of data, and limitations on the use of data&nbsp;to train other products or models.&nbsp;Beyond contractual safeguards, the Government has also implemented technical measures to screen sensitive data,&nbsp;visual&nbsp;cues to remind&nbsp;users on data security practices, and governance measures to enforce compliance.</p><p></p><p>We continuously re-assess the adequacy of our measures as the technology evolves.</p>